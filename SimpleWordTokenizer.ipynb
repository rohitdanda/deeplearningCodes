{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimpleWordTokenizer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO931VXmqKor7qrPNPlM4yj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohitdanda/deeplearningCodes/blob/master/SimpleWordTokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9UZ9fYkEqzt",
        "colab_type": "text"
      },
      "source": [
        "Here we simple convert our given senetence into first 100 common words\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jH0-KXND8vR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e5023c82-4a5a-4e50-d86d-38bb72efa2f9"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "sentence = [ 'MAchine','Find which word come first',\"Trying different word tokens\"]\n",
        "\n",
        "tokens = Tokenizer(num_words=100)\n",
        "tokens.fit_on_texts(sentence)\n",
        "word_indexs = tokens.word_index\n",
        "print(word_indexs)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'word': 1, 'machine': 2, 'find': 3, 'which': 4, 'come': 5, 'first': 6, 'trying': 7, 'different': 8, 'tokens': 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbtY9mwaF4bw",
        "colab_type": "text"
      },
      "source": [
        "Once we learn the word _index and make an dictonary of word with number we use this dictory for the unseen data. For suppose if the dictory of words dont have new word it will ignore those words in sequence\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsDcz5_UERPr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "394c672e-f957-478a-f2e8-a98aa8b435e6"
      },
      "source": [
        "newsentence = ['Hello Machine','Trying first word tokens']\n",
        "\n",
        "sequence = tokens.texts_to_sequences(newsentence)\n",
        "\n",
        "print(sequence)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2], [7, 6, 1, 9]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwYj1XYcHolI",
        "colab_type": "text"
      },
      "source": [
        "Below code we fix the missing sequence to the missing words or new word from word_index "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbrS7x0KHnIX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0c91610a-7391-49f9-eb0c-b61ae6c0c395"
      },
      "source": [
        "oovtokens = Tokenizer(num_words=100,oov_token='<r>')\n",
        "oovtokens.fit_on_texts(sentence)\n",
        "word_index = oovtokens.word_index\n",
        "print(word_index)\n",
        "sequence_fixed = oovtokens.texts_to_sequences(newsentence)\n",
        "print(sequence_fixed)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'<r>': 1, 'word': 2, 'machine': 3, 'find': 4, 'which': 5, 'come': 6, 'first': 7, 'trying': 8, 'different': 9, 'tokens': 10}\n",
            "[[1, 3], [8, 7, 2, 10]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GLtUhlfJ-qh",
        "colab_type": "text"
      },
      "source": [
        "we can add padding to sequence and make "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxrgzeEYJ7mg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "02bf61ac-65f0-4e34-8312-1cc4d70daaf3"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "padding = pad_sequences(sequence_fixed,padding='post',maxlen=3,truncating='post')\n",
        "print(padding)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 3 0]\n",
            " [8 7 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}